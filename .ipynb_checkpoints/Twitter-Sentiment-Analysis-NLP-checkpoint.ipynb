{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:43:05.717831Z",
     "start_time": "2021-05-05T20:43:05.696219Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries required to load, transform, analyze and plot data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(context='paper', style='darkgrid', \n",
    "        rc={'figure.facecolor':'white'}, font_scale=1.2)\n",
    "\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.tokenizer import _get_regex_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:13.842408Z",
     "start_time": "2021-05-05T20:19:13.837015Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove scientific notation and restrictions on df rows/columns display\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:15.951857Z",
     "start_time": "2021-05-05T20:19:15.898784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "          directed_at     emotion_label  \n",
       "0              iPhone  Negative emotion  \n",
       "1  iPad or iPhone App  Positive emotion  \n",
       "2                iPad  Positive emotion  \n",
       "3  iPad or iPhone App  Negative emotion  \n",
       "4              Google  Positive emotion  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load primary source file to df, renaming columns, dropping non-ASCII\n",
    "col_names = ['tweet_text', 'directed_at', 'emotion_label']\n",
    "tweets = pd.read_csv('data/judge-1377884607_tweet_product_company.csv', encoding= 'unicode_escape', names=col_names, header=0)\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:17.771711Z",
     "start_time": "2021-05-05T20:19:17.750696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweet_text     9092 non-null   object\n",
      " 1   directed_at    3291 non-null   object\n",
      " 2   emotion_label  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# review data types and null counts\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:19.718549Z",
     "start_time": "2021-05-05T20:19:19.704908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop nan tweets from dataframe\n",
    "tweets.dropna(subset = ['tweet_text'], inplace=True)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:20.839689Z",
     "start_time": "2021-05-05T20:19:20.828817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN                               0.638\n",
      "iPad                              0.104\n",
      "Apple                             0.073\n",
      "iPad or iPhone App                0.052\n",
      "Google                            0.047\n",
      "iPhone                            0.033\n",
      "Other Google product or service   0.032\n",
      "Android App                       0.009\n",
      "Android                           0.009\n",
      "Other Apple product or service    0.004\n",
      "Name: directed_at, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check value counts by column\n",
    "print(tweets['directed_at'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:22.738093Z",
     "start_time": "2021-05-05T20:19:22.725092Z"
    }
   },
   "outputs": [],
   "source": [
    "# create brand feature\n",
    "tweets['directed_at'].fillna('None', inplace=True)\n",
    "brand_map = {'iPad': 'Apple', 'Apple': 'Apple', 'iPad or iPhone App': 'Apple', \n",
    "             'Google': 'Google', 'iPhone': 'Apple', \n",
    "             'Other Google product or service': 'Google',\n",
    "            'Android App': 'Google', 'Android': 'Google',\n",
    "             'Other Apple product or service': 'Apple',\n",
    "             'None': 'None'\n",
    "            }\n",
    "tweets['brand'] = tweets.directed_at.map(brand_map, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:23.683232Z",
     "start_time": "2021-05-05T20:19:23.667013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral    0.593\n",
      "Positive   0.328\n",
      "Negative   0.063\n",
      "Unknown    0.017\n",
      "Name: emotion_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# clean emotion labels\n",
    "tweets['emotion_label'].replace({'No emotion toward brand or product': 'Neutral',\n",
    "                                 'Positive emotion': 'Positive', \n",
    "                                 'Negative emotion': 'Negative', \n",
    "                                 'I can\\'t tell': 'Unknown'}, inplace=True)\n",
    "\n",
    "# check value counts by column\n",
    "print(tweets['emotion_label'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:25.904427Z",
     "start_time": "2021-05-05T20:19:25.889178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand   emotion_label\n",
       "Apple   Negative          388\n",
       "        Neutral            65\n",
       "        Positive         1949\n",
       "        Unknown             7\n",
       "Google  Negative          131\n",
       "        Neutral            26\n",
       "        Positive          723\n",
       "        Unknown             2\n",
       "None    Negative           51\n",
       "        Neutral          5297\n",
       "        Positive          306\n",
       "        Unknown           147\n",
       "Name: tweet_text, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check value counts by column\n",
    "tweets.groupby(by=['brand', 'emotion_label'])['tweet_text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Text Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:28.365108Z",
     "start_time": "2021-05-05T20:19:28.359600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation Count: 31 Sample 5: ['!', '\"', '$', '%', '&']\n"
     ]
    }
   ],
   "source": [
    "# Get all the stop words and punctuation in the English language\n",
    "punctuation = list(string.punctuation)\n",
    "punctuation.remove('#') # keep # for hashtags\n",
    "\n",
    "# sample stopwods and punctuations\n",
    "print(f'Punctuation Count: {len(punctuation)} Sample 5: {punctuation[0:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:30.088526Z",
     "start_time": "2021-05-05T20:19:30.081272Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(x):\n",
    "    \"\"\"\n",
    "    Helper function to remove punctuation from a string x: any string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = re.sub('@[A-Za-z0-9]+', '', x) # remove @mention users\n",
    "        x = re.sub(r'http\\S+', '', x) # remove URL references\n",
    "        x = re.sub(r'\\b[0-9]+\\b', '', x) # remove stand-alone numbers  \n",
    "        x = ''.join(ch for ch in x if ch not in punctuation) # remove punc\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:31.517799Z",
     "start_time": "2021-05-05T20:19:31.513372Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to clean text\n",
    "def  clean_text(df, text_field, new_text_field):\n",
    "    df[new_text_field] = df[text_field].str.lower()\n",
    "    df[new_text_field] = df[new_text_field].apply(remove_punctuation) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:19:32.622473Z",
     "start_time": "2021-05-05T20:19:32.116373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>brand</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple</td>\n",
       "      <td>i have a 3g iphone after  hrs tweeting at #riseaustin it was dead  i need to upgrade plugin stations at #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple</td>\n",
       "      <td>know about   awesome ipadiphone app that youll likely appreciate for its design also theyre giving free ts at #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple</td>\n",
       "      <td>can not wait for #ipad  also they should sale them down at #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple</td>\n",
       "      <td>i hope this years festival isnt as crashy as this years iphone app #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Google</td>\n",
       "      <td>great stuff on fri #sxsw marissa mayer google tim oreilly tech booksconferences amp matt mullenweg wordpress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "          directed_at emotion_label   brand  \\\n",
       "0              iPhone      Negative   Apple   \n",
       "1  iPad or iPhone App      Positive   Apple   \n",
       "2                iPad      Positive   Apple   \n",
       "3  iPad or iPhone App      Negative   Apple   \n",
       "4              Google      Positive  Google   \n",
       "\n",
       "                                                                                                       tweet_text_clean  \n",
       "0         i have a 3g iphone after  hrs tweeting at #riseaustin it was dead  i need to upgrade plugin stations at #sxsw  \n",
       "1   know about   awesome ipadiphone app that youll likely appreciate for its design also theyre giving free ts at #sxsw  \n",
       "2                                                      can not wait for #ipad  also they should sale them down at #sxsw  \n",
       "3                                              i hope this years festival isnt as crashy as this years iphone app #sxsw  \n",
       "4          great stuff on fri #sxsw marissa mayer google tim oreilly tech booksconferences amp matt mullenweg wordpress  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean = clean_text(tweets, 'tweet_text', 'tweet_text_clean')\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:26:48.676104Z",
     "start_time": "2021-05-05T20:26:47.915857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "nlp = en_core_web_sm.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n",
    "# overwrite token_match function of the tokenizer\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:32:44.503731Z",
     "start_time": "2021-05-05T20:27:06.456313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Stopword Count: 326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>brand</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "      <th>tokens_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple</td>\n",
       "      <td>i have a 3g iphone after  hrs tweeting at #riseaustin it was dead  i need to upgrade plugin stations at #sxsw</td>\n",
       "      <td>[g, iphone, hrs, tweet, #riseaustin, dead, need, upgrade, plugin, station, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple</td>\n",
       "      <td>know about   awesome ipadiphone app that youll likely appreciate for its design also theyre giving free ts at #sxsw</td>\n",
       "      <td>[know, awesome, ipadiphone, app, will, likely, appreciate, design, give, free, ts, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Apple</td>\n",
       "      <td>can not wait for #ipad  also they should sale them down at #sxsw</td>\n",
       "      <td>[wait, #ipad, sale, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Apple</td>\n",
       "      <td>i hope this years festival isnt as crashy as this years iphone app #sxsw</td>\n",
       "      <td>[hope, year, festival, not, crashy, year, iphone, app, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Google</td>\n",
       "      <td>great stuff on fri #sxsw marissa mayer google tim oreilly tech booksconferences amp matt mullenweg wordpress</td>\n",
       "      <td>[great, stuff, fri, #sxsw, marissa, mayer, google, tim, oreilly, tech, booksconference, amp, matt, mullenweg, wordpress]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "          directed_at emotion_label   brand  \\\n",
       "0              iPhone      Negative   Apple   \n",
       "1  iPad or iPhone App      Positive   Apple   \n",
       "2                iPad      Positive   Apple   \n",
       "3  iPad or iPhone App      Negative   Apple   \n",
       "4              Google      Positive  Google   \n",
       "\n",
       "                                                                                                       tweet_text_clean  \\\n",
       "0         i have a 3g iphone after  hrs tweeting at #riseaustin it was dead  i need to upgrade plugin stations at #sxsw   \n",
       "1   know about   awesome ipadiphone app that youll likely appreciate for its design also theyre giving free ts at #sxsw   \n",
       "2                                                      can not wait for #ipad  also they should sale them down at #sxsw   \n",
       "3                                              i hope this years festival isnt as crashy as this years iphone app #sxsw   \n",
       "4          great stuff on fri #sxsw marissa mayer google tim oreilly tech booksconferences amp matt mullenweg wordpress   \n",
       "\n",
       "                                                                                                                  tokens_sp  \n",
       "0                                         [g, iphone, hrs, tweet, #riseaustin, dead, need, upgrade, plugin, station, #sxsw]  \n",
       "1                                 [know, awesome, ipadiphone, app, will, likely, appreciate, design, give, free, ts, #sxsw]  \n",
       "2                                                                                                [wait, #ipad, sale, #sxsw]  \n",
       "3                                                             [hope, year, festival, not, crashy, year, iphone, app, #sxsw]  \n",
       "4  [great, stuff, fri, #sxsw, marissa, mayer, google, tim, oreilly, tech, booksconference, amp, matt, mullenweg, wordpress]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "stops_sp = nlp.Defaults.stop_words\n",
    "print(f'spaCy Stopword Count: {len(stops_sp)}')\n",
    "\n",
    "def clean_token(doc):\n",
    "    return [token.lemma_ for token in doc if not token.is_stop \n",
    "            and not token.is_punct and not token.is_digit \n",
    "            and not token.is_space]\n",
    "\n",
    "tweets['tokens_sp'] = [clean_token(nlp(row)) for row in tweets.tweet_text_clean.apply(str)]\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:32:44.534638Z",
     "start_time": "2021-05-05T20:32:44.505041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#sxsw', 8947),\n",
       " ('link', 4300),\n",
       " ('rt', 2953),\n",
       " ('ipad', 2245),\n",
       " ('google', 2102),\n",
       " ('apple', 1826),\n",
       " ('store', 1501),\n",
       " ('iphone', 1258),\n",
       " ('new', 1093),\n",
       " ('app', 992),\n",
       " ('austin', 848),\n",
       " ('launch', 819),\n",
       " ('amp', 724),\n",
       " ('social', 623),\n",
       " ('popup', 600),\n",
       " ('today', 573),\n",
       " ('open', 514),\n",
       " ('not', 496),\n",
       " ('sxsw', 481),\n",
       " ('network', 472),\n",
       " ('line', 446),\n",
       " ('circle', 444),\n",
       " ('android', 435),\n",
       " ('#apple', 409),\n",
       " ('party', 380)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "word_dict = {}\n",
    "\n",
    "# Loop through all the tags\n",
    "for i, row in tweets['tokens_sp'].iteritems():\n",
    "    for word in row:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = 1\n",
    "        else:\n",
    "            word_dict[word] +=1\n",
    "\n",
    "word_counts = sorted(word_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(f'Total words: {len(word_counts)}')\n",
    "word_counts[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:34:15.054520Z",
     "start_time": "2021-05-05T20:34:15.031745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            [g, iphone, hrs, tweet, #riseaustin, dead, need, upgrade, plugin, station, #sxsw]\n",
      "1    [know, awesome, ipadiphone, app, will, likely, appreciate, design, give, free, ts, #sxsw]\n",
      "2                                                                   [wait, #ipad, sale, #sxsw]\n",
      "Name: tokens_sp, dtype: object    Negative  Neutral  Positive\n",
      "0         1        0         0\n",
      "1         0        0         1\n",
      "2         0        0         1\n"
     ]
    }
   ],
   "source": [
    "# filter tweets for identifiable emotions only (drop unknown)\n",
    "sentiments = ['Positive', 'Negative', 'Neutral']\n",
    "tweets_f = tweets[tweets['emotion_label'].isin(sentiments)]\n",
    "\n",
    "# create X and y (one-hot encoded for 3 classes)\n",
    "X = tweets_f['tokens_sp']\n",
    "y = pd.get_dummies(tweets_f['emotion_label'])\n",
    "print(X.iloc[:3], y.iloc[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:34:17.761414Z",
     "start_time": "2021-05-05T20:34:17.709494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7148,) X_test: (1788,) y_train: (7148, 3) y_test: (1788, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test sets\n",
    "SEED = 19\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=SEED)\n",
    "print(f'X_train: {X_train.shape} X_test: {X_test.shape} ' \n",
    "      f'y_train: {y_train.shape} y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:40:34.406641Z",
     "start_time": "2021-05-05T20:40:34.269781Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenized_tweets = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq = sequence.pad_sequences(tokenized_tweets, maxlen=25) # longest 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:44:45.959823Z",
     "start_time": "2021-05-05T20:44:45.808319Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_size = 25\n",
    "model.add(Embedding(20000, embedding_size))\n",
    "model.add(LSTM(25, return_sequences=True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:44:48.411784Z",
     "start_time": "2021-05-05T20:44:48.357328Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:45:09.305667Z",
     "start_time": "2021-05-05T20:45:09.298848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 25)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 25)          5100      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 506,553\n",
      "Trainable params: 506,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T20:46:41.125532Z",
     "start_time": "2021-05-05T20:46:06.270610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cutterback/opt/anaconda3/envs/p37env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6075 samples, validate on 1073 samples\n",
      "Epoch 1/3\n",
      "6075/6075 [==============================] - 14s 2ms/step - loss: 0.9156 - accuracy: 0.5852 - val_loss: 0.8449 - val_accuracy: 0.5983\n",
      "Epoch 2/3\n",
      "6075/6075 [==============================] - 11s 2ms/step - loss: 0.8359 - accuracy: 0.6069 - val_loss: 0.7969 - val_accuracy: 0.6067\n",
      "Epoch 3/3\n",
      "6075/6075 [==============================] - 10s 2ms/step - loss: 0.7301 - accuracy: 0.6683 - val_loss: 0.7417 - val_accuracy: 0.6524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f93b24ec910>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, y_train, epochs=3, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p37env] *",
   "language": "python",
   "name": "conda-env-p37env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
